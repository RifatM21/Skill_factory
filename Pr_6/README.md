## Цель проекта:

Создать модель, которая будет предсказывать стоимость автомобиля по его характеристикам.

Так как в данном проекте нет начального датасета, на котором будет обучаться модель, необходимо его собрать самому.

#### 1. Получение списка ссылок на характеристики автомобилей

Для сборки собственного датасета, сперва были получены ссылки на страницы автомобилей с пробегом в городе Москва. Код для получения текстового файла _links.txt_ находится в файле _Links_parser.py_.

Основная проблема, с которой столкнулся при выполнении данного пункта, была - наличие капчи при каждом новом `.get()` запросе (открытом окне) с помощью библиотеки `selenium`. В качестве решения данной проблемы было решено использовать самый банальный метод - нажатие на кнопку подтвержедния при помощи метода `.click()`.

#### 2. Получение характеристик автомобилей

Следующим шагом данного проекта являлся сбор датасета с характеристиками автомобилей. Для этого для каждой ссылки, из полученного ранее файла _links.txt_, создавался отдельный `.get()` запрос и собиралась основная информация о машине: название модели, цена, технические характеристики, комплектация, старана производитель и количество дверей. По данным карактеристикам был собран датасет, на котором будет обучаться будущая модель.

Основная проблема данного пункта состояла в том, что разные характеристики находились на разных подстраницах, в связи с чем приходилось посылать дополнительные `.get()` запросы на эти подстраницы. Также, в качестве проблемы можно выделить текущую ситуация в мире, и то, что пока собирались характеристики по, ранее полученным, ссылкам, многие автомобили были либо проданы, либо убраны с продажи (около 30%). Поэтому полученный датасет был недостаточно полным.

Код для данного этапа можно посмотреть в файле _Data_parser.py_

#### 3. Очистка данных и приведение к одному виду тестовых и обучающих данных

Так как формат данных, которые были получены при парсинге, сильно отличается от того, который находится на _kaggle_, необходимо было привести их к схожему виду. Для этого были выполнены специальные преобразования почти для каждого отдельного столбца (признака) в файле _data_prepare.py_.

Одним из главных преобразований было - перевод цены из руб. в $, т.к в настоящее время курс рубля сильно изменился относительно времени, когда был составлен тестовый датасет.

#### 4. Составление модели

Заключающим этапом данного проекта было составление модели, обучение её на полученном датасете и далее предсказние цены автомобилей в тестовом датасете.

Сперва был произведён разведовательный анализ тренировачного датасета, где были рассмотрены некоторые зависимости цены от конкретных показателей, а также график корреляции численных переменных. На основе этих зависимостей были убраны лишние признаки.

Далее были составленны некоторые дополнительные признаки, основанные на средних показателях признаков. После чего из категориальных признаков были получены `dummy` признаки.

В качестве начальной модели, была использована стандартная линейная регрессия - `LinearRegression()`. Данная модель показала результат MAPE = 2.5 %.

Следующей моделью были случайные леса без гиперпараметров - `RandomForestRegressor()`, данная модель показала MAPE = 2.2 %. При подборе гиперпараметров с помощью метода `RandomizedSearchCV()`, данная модель показала MAPE = 1.9 %.

Последней моделью была линейная регрессия, использующая новые показатели, полученные при помощи стэкинга линейной регресси и случайных лесов с гиперпараметрами. Данная модель показала MAPE = 1.5 %.

Все значения можно посмотреть в файле _model.py_

### НО:

В ходе предсказния цены уже для тестовой выборки с _kaggle_, я столскнулся с проблемой, которую так и не понял, как решить. 

Проблема заключается в следующем: если мы обучаем модель при помощи стэкинга (в моём случае это стэкинг 2 моделей), то в итоге получается так, что для предсказания цены, на вход такой модели должен подаваться датасет из 2 признаков, так как при стэкинг для регрессии мы получаем только по 1 дополнительному признаку с каждой модели, которую мы используем в стэкинге. И в итоге для моделей в стэкинге я использовал нормальные датасеты, в которых было по 73 признака, они обучались, возвращали свои предсказания, которые становились новыми признаками, и уже на основе новых признаком обучалась конечная модель (была выбрана линейная регрессия), т.е конечная модель обучалась на 2 признаках. В то же время, если я хотел бы сделать предсказние с помщью этой модели для тестовой выборки, я бы не мог этого сделать, так как в ней 73 признака, а не 2, полученные при стэкинге.

Хотелось бы по этому вопросу узнать разъяснение. Как сделать предсказние для тестового датасета, у которого 73 признака, если модель принимает только 2 признака при стэкинге?


## Итог

В итоге было решено использовать модель случайного леса с наилучшемы гиперпараметрами.

Конечный результат MAPE на _kaggle_ = 19 %.
